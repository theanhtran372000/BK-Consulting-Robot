{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 5769k  100 5769k    0     0  1832k      0  0:00:03  0:00:03 --:--:-- 1832k\n",
      "saved_model/openvino/FP32/face_detection_yunet_120x160.xml\n",
      "saved_model/saved_model.pb\n",
      "saved_model/openvino/FP16/face_detection_yunet_120x160.mapping\n",
      "saved_model/model_integer_quant.tflite\n",
      "saved_model/face_detection_yunet_120x160.onnx\n",
      "saved_model/model_float16_quant.tflite\n",
      "saved_model/tensorrt_saved_model_float16/variables/variables.data-00000-of-00001\n",
      "saved_model/openvino/myriad/face_detection_yunet_120x160.blob\n",
      "saved_model/tensorrt_saved_model_float16/variables/\n",
      "saved_model/tensorrt_saved_model_float32/variables/variables.index\n",
      "saved_model/tfjs_model_float32/\n",
      "saved_model/tensorrt_saved_model_float16/assets/\n",
      "saved_model/model_coreml_float32.mlmodel\n",
      "saved_model/variables/variables.data-00000-of-00001\n",
      "saved_model/tensorrt_saved_model_float16/assets/trt-serialized-engine.TRTEngineOp_1_1\n",
      "saved_model/tensorrt_saved_model_float32/\n",
      "saved_model/tfjs_model_float32/model.json\n",
      "saved_model/openvino/FP32/face_detection_yunet_120x160.bin\n",
      "saved_model/openvino/myriad/\n",
      "saved_model/tensorrt_saved_model_float32/variables/variables.data-00000-of-00001\n",
      "saved_model/model_weight_quant.tflite\n",
      "saved_model/tfjs_model_float16/\n",
      "saved_model/model_full_integer_quant_edgetpu.log\n",
      "saved_model/variables/variables.index\n",
      "saved_model/model_float32.pb\n",
      "saved_model/tensorrt_saved_model_float16/\n",
      "saved_model/tensorrt_saved_model_float16/assets/trt-serialized-engine.TRTEngineOp_1_0\n",
      "saved_model/openvino/FP32/\n",
      "saved_model/tensorrt_saved_model_float32/assets/trt-serialized-engine.TRTEngineOp_0_1\n",
      "saved_model/openvino/FP32/face_detection_yunet_120x160.mapping\n",
      "saved_model/tensorrt_saved_model_float32/saved_model.pb\n",
      "saved_model/tfjs_model_float16/group1-shard1of1.bin\n",
      "saved_model/\n",
      "saved_model/variables/\n",
      "saved_model/openvino/FP16/face_detection_yunet_120x160.bin\n",
      "saved_model/tensorrt_saved_model_float32/assets/\n",
      "saved_model/tensorrt_saved_model_float16/variables/variables.index\n",
      "saved_model/model_full_integer_quant.tflite\n",
      "saved_model/tensorrt_saved_model_float32/assets/trt-serialized-engine.TRTEngineOp_0_0\n",
      "saved_model/assets/\n",
      "saved_model/model_full_integer_quant_edgetpu.tflite\n",
      "saved_model/openvino/\n",
      "saved_model/openvino/FP16/\n",
      "saved_model/model_float32.tflite\n",
      "saved_model/tfjs_model_float16/model.json\n",
      "saved_model/tfjs_model_float32/group1-shard1of1.bin\n",
      "saved_model/tensorrt_saved_model_float32/variables/\n",
      "saved_model/openvino/FP16/face_detection_yunet_120x160.xml\n",
      "saved_model/tensorrt_saved_model_float16/saved_model.pb\n",
      "Download finished.\n"
     ]
    }
   ],
   "source": [
    "# Download ONNX model\n",
    "# !git clone https://github.com/PINTO0309/PINTO_model_zoo.git\n",
    "# %cd PINTO_model_zoo/144_YuNet\n",
    "!./download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=./saved_model/face_detection_yunet_120x160.onnx\n",
      "[04/19/2023-10:01:50] [I] === Model Options ===\n",
      "[04/19/2023-10:01:50] [I] Format: ONNX\n",
      "[04/19/2023-10:01:50] [I] Model: ./saved_model/face_detection_yunet_120x160.onnx\n",
      "[04/19/2023-10:01:50] [I] Output:\n",
      "[04/19/2023-10:01:50] [I] === Build Options ===\n",
      "[04/19/2023-10:01:50] [I] Max batch: explicit batch\n",
      "[04/19/2023-10:01:50] [I] Workspace: 16 MiB\n",
      "[04/19/2023-10:01:50] [I] minTiming: 1\n",
      "[04/19/2023-10:01:50] [I] avgTiming: 8\n",
      "[04/19/2023-10:01:50] [I] Precision: FP32\n",
      "[04/19/2023-10:01:50] [I] Calibration: \n",
      "[04/19/2023-10:01:50] [I] Refit: Disabled\n",
      "[04/19/2023-10:01:50] [I] Sparsity: Disabled\n",
      "[04/19/2023-10:01:50] [I] Safe mode: Disabled\n",
      "[04/19/2023-10:01:50] [I] DirectIO mode: Disabled\n",
      "[04/19/2023-10:01:50] [I] Restricted mode: Disabled\n",
      "[04/19/2023-10:01:50] [I] Save engine: \n",
      "[04/19/2023-10:01:50] [I] Load engine: \n",
      "[04/19/2023-10:01:50] [I] Profiling verbosity: 0\n",
      "[04/19/2023-10:01:50] [I] Tactic sources: Using default tactic sources\n",
      "[04/19/2023-10:01:50] [I] timingCacheMode: local\n",
      "[04/19/2023-10:01:50] [I] timingCacheFile: \n",
      "[04/19/2023-10:01:50] [I] Input(s)s format: fp32:CHW\n",
      "[04/19/2023-10:01:50] [I] Output(s)s format: fp32:CHW\n",
      "[04/19/2023-10:01:50] [I] Input build shapes: model\n",
      "[04/19/2023-10:01:50] [I] Input calibration shapes: model\n",
      "[04/19/2023-10:01:50] [I] === System Options ===\n",
      "[04/19/2023-10:01:50] [I] Device: 0\n",
      "[04/19/2023-10:01:50] [I] DLACore: \n",
      "[04/19/2023-10:01:50] [I] Plugins:\n",
      "[04/19/2023-10:01:50] [I] === Inference Options ===\n",
      "[04/19/2023-10:01:50] [I] Batch: Explicit\n",
      "[04/19/2023-10:01:50] [I] Input inference shapes: model\n",
      "[04/19/2023-10:01:50] [I] Iterations: 10\n",
      "[04/19/2023-10:01:50] [I] Duration: 3s (+ 200ms warm up)\n",
      "[04/19/2023-10:01:50] [I] Sleep time: 0ms\n",
      "[04/19/2023-10:01:50] [I] Idle time: 0ms\n",
      "[04/19/2023-10:01:50] [I] Streams: 1\n",
      "[04/19/2023-10:01:50] [I] ExposeDMA: Disabled\n",
      "[04/19/2023-10:01:50] [I] Data transfers: Enabled\n",
      "[04/19/2023-10:01:50] [I] Spin-wait: Disabled\n",
      "[04/19/2023-10:01:50] [I] Multithreading: Disabled\n",
      "[04/19/2023-10:01:50] [I] CUDA Graph: Disabled\n",
      "[04/19/2023-10:01:50] [I] Separate profiling: Disabled\n",
      "[04/19/2023-10:01:50] [I] Time Deserialize: Disabled\n",
      "[04/19/2023-10:01:50] [I] Time Refit: Disabled\n",
      "[04/19/2023-10:01:50] [I] Skip inference: Disabled\n",
      "[04/19/2023-10:01:50] [I] Inputs:\n",
      "[04/19/2023-10:01:50] [I] === Reporting Options ===\n",
      "[04/19/2023-10:01:50] [I] Verbose: Disabled\n",
      "[04/19/2023-10:01:50] [I] Averages: 10 inferences\n",
      "[04/19/2023-10:01:50] [I] Percentile: 99\n",
      "[04/19/2023-10:01:50] [I] Dump refittable layers:Disabled\n",
      "[04/19/2023-10:01:50] [I] Dump output: Disabled\n",
      "[04/19/2023-10:01:50] [I] Profile: Disabled\n",
      "[04/19/2023-10:01:50] [I] Export timing to JSON file: \n",
      "[04/19/2023-10:01:50] [I] Export output to JSON file: \n",
      "[04/19/2023-10:01:50] [I] Export profile to JSON file: \n",
      "[04/19/2023-10:01:50] [I] \n",
      "[04/19/2023-10:01:50] [I] === Device Information ===\n",
      "[04/19/2023-10:01:50] [I] Selected Device: NVIDIA Tegra X1\n",
      "[04/19/2023-10:01:50] [I] Compute Capability: 5.3\n",
      "[04/19/2023-10:01:50] [I] SMs: 1\n",
      "[04/19/2023-10:01:50] [I] Compute Clock Rate: 0.9216 GHz\n",
      "[04/19/2023-10:01:50] [I] Device Global Memory: 3964 MiB\n",
      "[04/19/2023-10:01:50] [I] Shared Memory per SM: 64 KiB\n",
      "[04/19/2023-10:01:50] [I] Memory Bus Width: 64 bits (ECC disabled)\n",
      "[04/19/2023-10:01:50] [I] Memory Clock Rate: 0.01275 GHz\n",
      "[04/19/2023-10:01:50] [I] \n",
      "[04/19/2023-10:01:50] [I] TensorRT version: 8.2.1\n",
      "[04/19/2023-10:01:54] [I] [TRT] [MemUsageChange] Init CUDA: CPU +229, GPU +0, now: CPU 248, GPU 3767 (MiB)\n",
      "[04/19/2023-10:01:55] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 248 MiB, GPU 3771 MiB\n",
      "[04/19/2023-10:01:55] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 278 MiB, GPU 3773 MiB\n",
      "[04/19/2023-10:01:55] [I] Start parsing network model\n",
      "[04/19/2023-10:01:55] [I] [TRT] ----------------------------------------------------------------\n",
      "[04/19/2023-10:01:55] [I] [TRT] Input filename:   ./saved_model/face_detection_yunet_120x160.onnx\n",
      "[04/19/2023-10:01:55] [I] [TRT] ONNX IR version:  0.0.6\n",
      "[04/19/2023-10:01:55] [I] [TRT] Opset version:    9\n",
      "[04/19/2023-10:01:55] [I] [TRT] Producer name:    pytorch\n",
      "[04/19/2023-10:01:55] [I] [TRT] Producer version: 1.9\n",
      "[04/19/2023-10:01:55] [I] [TRT] Domain:           \n",
      "[04/19/2023-10:01:55] [I] [TRT] Model version:    0\n",
      "[04/19/2023-10:01:55] [I] [TRT] Doc string:       \n",
      "[04/19/2023-10:01:55] [I] [TRT] ----------------------------------------------------------------\n",
      "[04/19/2023-10:01:55] [W] [TRT] onnx2trt_utils.cpp:366: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[04/19/2023-10:01:55] [I] Finish parsing network model\n",
      "[04/19/2023-10:01:55] [I] [TRT] ---------- Layers Running on DLA ----------\n",
      "[04/19/2023-10:01:55] [I] [TRT] ---------- Layers Running on GPU ----------\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_0 + Relu_1\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_2\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_3 + Relu_4\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] MaxPool_5\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_6\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_7 + Relu_8\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_9\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_10 + Relu_11\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_12\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_13 + Relu_14\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_15\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_16 + Relu_17\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] MaxPool_18\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_19\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_20 + Relu_21\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_22\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_23 + Relu_24\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] MaxPool_25\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_26\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_27 + Relu_28\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_29\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_30 + Relu_31\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] MaxPool_32\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_33\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_34 + Relu_35\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_36\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_37 + Relu_38\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] MaxPool_39\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_40\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_41 + Relu_42\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_43\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_44 + Relu_45\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_46\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_47 + Relu_48\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_49\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_50\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_52\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_53 + Relu_54\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_55\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_56\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_58\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_59 + Relu_60\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_61\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_62\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_64\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_65 + Relu_66\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_67\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Conv_68\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Transpose_51 + Reshape_75\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Transpose_57 + Reshape_81\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Transpose_63 + Reshape_87\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Transpose_69 + Reshape_93\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Reshape_100\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Slice_101\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Slice_102\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Slice_103\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Reshape_105\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Reshape_107 + (Unnamed Layer* 81) [Shuffle]\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Softmax_108\n",
      "[04/19/2023-10:01:55] [I] [TRT] [GpuLayer] Reshape_110\n",
      "[04/19/2023-10:01:58] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +34, now: CPU 437, GPU 3813 (MiB)\n",
      "[04/19/2023-10:02:02] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +240, GPU +34, now: CPU 677, GPU 3847 (MiB)\n",
      "[04/19/2023-10:02:02] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[04/19/2023-10:02:18] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[04/19/2023-10:03:03] [I] [TRT] Detected 1 inputs and 3 output network tensors.\n",
      "[04/19/2023-10:03:03] [I] [TRT] Total Host Persistent Memory: 56832\n",
      "[04/19/2023-10:03:03] [I] [TRT] Total Device Persistent Memory: 254464\n",
      "[04/19/2023-10:03:03] [I] [TRT] Total Scratch Memory: 0\n",
      "[04/19/2023-10:03:03] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 13 MiB\n",
      "[04/19/2023-10:03:03] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 8.72745ms to assign 6 blocks to 54 nodes requiring 654848 bytes.\n",
      "[04/19/2023-10:03:03] [I] [TRT] Total Activation Memory: 654848\n",
      "[04/19/2023-10:03:03] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU -17, now: CPU 920, GPU 3879 (MiB)\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +3, now: CPU 921, GPU 3882 (MiB)\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 920, GPU 3882 (MiB)\n",
      "[04/19/2023-10:03:04] [I] [TRT] Loaded engine size: 0 MiB\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +0, now: CPU 921, GPU 3882 (MiB)\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 921, GPU 3882 (MiB)\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n",
      "[04/19/2023-10:03:04] [I] Engine built in 73.6823 sec.\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 890, GPU 3886 (MiB)\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 890, GPU 3886 (MiB)\n",
      "[04/19/2023-10:03:04] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1, now: CPU 0, GPU 1 (MiB)\n",
      "[04/19/2023-10:03:04] [I] Using random values for input input\n",
      "[04/19/2023-10:03:04] [I] Created input binding for input with dimensions 1x3x120x160\n",
      "[04/19/2023-10:03:04] [I] Using random values for output loc\n",
      "[04/19/2023-10:03:04] [I] Created output binding for loc with dimensions 1076x14\n",
      "[04/19/2023-10:03:04] [I] Using random values for output conf\n",
      "[04/19/2023-10:03:04] [I] Created output binding for conf with dimensions 1076x2\n",
      "[04/19/2023-10:03:04] [I] Using random values for output iou\n",
      "[04/19/2023-10:03:04] [I] Created output binding for iou with dimensions 1076x1\n",
      "[04/19/2023-10:03:04] [I] Starting inference\n",
      "[04/19/2023-10:03:07] [I] Warmup completed 45 queries over 200 ms\n",
      "[04/19/2023-10:03:07] [I] Timing trace has 1050 queries over 3.00208 s\n",
      "[04/19/2023-10:03:07] [I] \n",
      "[04/19/2023-10:03:07] [I] === Trace details ===\n",
      "[04/19/2023-10:03:07] [I] Trace averages of 10 runs:\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 4.01564 ms - Host latency: 4.29788 ms (end to end 4.40481 ms, enqueue 3.985 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 4.08592 ms - Host latency: 4.36928 ms (end to end 4.46979 ms, enqueue 4.05407 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 4.1773 ms - Host latency: 4.43854 ms (end to end 4.53371 ms, enqueue 4.11782 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 4.59073 ms - Host latency: 4.90254 ms (end to end 5.0118 ms, enqueue 4.55537 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 4.13243 ms - Host latency: 4.41886 ms (end to end 4.51782 ms, enqueue 4.10133 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 4.0322 ms - Host latency: 4.31324 ms (end to end 4.41254 ms, enqueue 4.00065 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 3.16936 ms - Host latency: 3.38827 ms (end to end 3.46806 ms, enqueue 3.13927 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.3137 ms - Host latency: 2.47279 ms (end to end 2.52618 ms, enqueue 2.28762 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.27314 ms - Host latency: 2.43116 ms (end to end 2.47756 ms, enqueue 2.24843 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.37578 ms - Host latency: 2.53632 ms (end to end 2.58491 ms, enqueue 2.34997 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.27239 ms - Host latency: 2.42934 ms (end to end 2.47646 ms, enqueue 2.24471 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.63711 ms - Host latency: 2.81449 ms (end to end 2.86727 ms, enqueue 2.60848 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.40244 ms - Host latency: 2.56843 ms (end to end 2.61827 ms, enqueue 2.37648 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.29931 ms - Host latency: 2.44706 ms (end to end 2.49131 ms, enqueue 2.25946 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.3795 ms - Host latency: 2.57236 ms (end to end 2.62552 ms, enqueue 2.38026 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.29045 ms - Host latency: 2.44882 ms (end to end 2.49658 ms, enqueue 2.26615 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.34374 ms - Host latency: 2.5086 ms (end to end 2.5559 ms, enqueue 2.3183 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.31138 ms - Host latency: 2.47278 ms (end to end 2.52068 ms, enqueue 2.28545 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.40513 ms - Host latency: 2.57573 ms (end to end 2.6276 ms, enqueue 2.37878 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.49094 ms - Host latency: 2.65546 ms (end to end 2.70767 ms, enqueue 2.46243 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.48431 ms - Host latency: 2.6506 ms (end to end 2.70145 ms, enqueue 2.45565 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.81973 ms - Host latency: 2.99816 ms (end to end 3.05463 ms, enqueue 2.78862 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.46704 ms - Host latency: 2.64106 ms (end to end 2.69715 ms, enqueue 2.43845 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.44315 ms - Host latency: 2.60742 ms (end to end 2.65871 ms, enqueue 2.41525 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.34117 ms - Host latency: 2.50458 ms (end to end 2.5524 ms, enqueue 2.31639 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.30245 ms - Host latency: 2.46639 ms (end to end 2.51406 ms, enqueue 2.27795 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.51138 ms - Host latency: 2.67738 ms (end to end 2.7291 ms, enqueue 2.48245 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.50938 ms - Host latency: 2.67544 ms (end to end 2.72528 ms, enqueue 2.48143 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.82255 ms - Host latency: 3.00292 ms (end to end 3.05929 ms, enqueue 2.78969 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.54188 ms - Host latency: 2.7094 ms (end to end 2.76149 ms, enqueue 2.51382 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.41587 ms - Host latency: 2.5848 ms (end to end 2.63813 ms, enqueue 2.38833 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.46267 ms - Host latency: 2.63097 ms (end to end 2.68262 ms, enqueue 2.43447 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4989 ms - Host latency: 2.66847 ms (end to end 2.72096 ms, enqueue 2.47089 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.48884 ms - Host latency: 2.65709 ms (end to end 2.70811 ms, enqueue 2.46053 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.52186 ms - Host latency: 2.68655 ms (end to end 2.73798 ms, enqueue 2.4937 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.43817 ms - Host latency: 2.60608 ms (end to end 2.65619 ms, enqueue 2.41091 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.50034 ms - Host latency: 2.6657 ms (end to end 2.7177 ms, enqueue 2.47233 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.67161 ms - Host latency: 2.84893 ms (end to end 2.90227 ms, enqueue 2.64188 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.50132 ms - Host latency: 2.66738 ms (end to end 2.71886 ms, enqueue 2.47297 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.41306 ms - Host latency: 2.57822 ms (end to end 2.62965 ms, enqueue 2.38536 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.38978 ms - Host latency: 2.55293 ms (end to end 2.60581 ms, enqueue 2.36362 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.37751 ms - Host latency: 2.53785 ms (end to end 2.58533 ms, enqueue 2.35264 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.41219 ms - Host latency: 2.57489 ms (end to end 2.62408 ms, enqueue 2.38531 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.47063 ms - Host latency: 2.64119 ms (end to end 2.69271 ms, enqueue 2.44265 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4277 ms - Host latency: 2.59531 ms (end to end 2.64509 ms, enqueue 2.40087 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.65695 ms - Host latency: 2.83066 ms (end to end 2.88427 ms, enqueue 2.62726 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.66261 ms - Host latency: 2.83636 ms (end to end 2.89037 ms, enqueue 2.63358 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.39091 ms - Host latency: 2.55334 ms (end to end 2.60339 ms, enqueue 2.36101 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.53757 ms - Host latency: 2.70681 ms (end to end 2.75985 ms, enqueue 2.50807 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.36708 ms - Host latency: 2.52991 ms (end to end 2.5786 ms, enqueue 2.34225 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.44666 ms - Host latency: 2.61034 ms (end to end 2.66207 ms, enqueue 2.41854 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.90641 ms - Host latency: 3.09343 ms (end to end 3.15021 ms, enqueue 2.87393 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.45748 ms - Host latency: 2.62369 ms (end to end 2.67806 ms, enqueue 2.42933 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.46058 ms - Host latency: 2.625 ms (end to end 2.67632 ms, enqueue 2.43253 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.48125 ms - Host latency: 2.64399 ms (end to end 2.69497 ms, enqueue 2.4536 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.44849 ms - Host latency: 2.61372 ms (end to end 2.66423 ms, enqueue 2.42035 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.48202 ms - Host latency: 2.65627 ms (end to end 2.70695 ms, enqueue 2.45417 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4842 ms - Host latency: 2.6506 ms (end to end 2.7019 ms, enqueue 2.45646 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.44875 ms - Host latency: 2.62261 ms (end to end 2.67469 ms, enqueue 2.42081 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.46787 ms - Host latency: 2.63315 ms (end to end 2.68428 ms, enqueue 2.43981 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.85404 ms - Host latency: 3.03335 ms (end to end 3.08994 ms, enqueue 2.82269 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4069 ms - Host latency: 2.57097 ms (end to end 2.62075 ms, enqueue 2.3795 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.47775 ms - Host latency: 2.64213 ms (end to end 2.69261 ms, enqueue 2.4496 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4917 ms - Host latency: 2.65576 ms (end to end 2.7071 ms, enqueue 2.46299 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.45994 ms - Host latency: 2.62935 ms (end to end 2.68076 ms, enqueue 2.43269 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.33965 ms - Host latency: 2.50142 ms (end to end 2.54941 ms, enqueue 2.3145 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.42903 ms - Host latency: 2.59392 ms (end to end 2.64419 ms, enqueue 2.40176 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.66101 ms - Host latency: 2.83474 ms (end to end 2.88645 ms, enqueue 2.63162 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.57722 ms - Host latency: 2.7616 ms (end to end 2.81963 ms, enqueue 2.54836 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.45427 ms - Host latency: 2.62493 ms (end to end 2.68884 ms, enqueue 2.4259 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4363 ms - Host latency: 2.59912 ms (end to end 2.64927 ms, enqueue 2.40879 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.44458 ms - Host latency: 2.6127 ms (end to end 2.66438 ms, enqueue 2.41553 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.44573 ms - Host latency: 2.61016 ms (end to end 2.66072 ms, enqueue 2.41914 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.43169 ms - Host latency: 2.59524 ms (end to end 2.64626 ms, enqueue 2.40361 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4771 ms - Host latency: 2.64133 ms (end to end 2.69868 ms, enqueue 2.44817 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.34651 ms - Host latency: 2.5073 ms (end to end 2.55562 ms, enqueue 2.32083 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4885 ms - Host latency: 2.65503 ms (end to end 2.70667 ms, enqueue 2.46025 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.72622 ms - Host latency: 2.90232 ms (end to end 2.95869 ms, enqueue 2.69578 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.56528 ms - Host latency: 2.73242 ms (end to end 2.78481 ms, enqueue 2.53672 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4324 ms - Host latency: 2.59961 ms (end to end 2.65068 ms, enqueue 2.40142 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.55942 ms - Host latency: 2.73245 ms (end to end 2.78521 ms, enqueue 2.53098 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.46392 ms - Host latency: 2.62825 ms (end to end 2.67905 ms, enqueue 2.43611 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.44939 ms - Host latency: 2.61472 ms (end to end 2.66545 ms, enqueue 2.42087 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.5519 ms - Host latency: 2.71963 ms (end to end 2.77739 ms, enqueue 2.52346 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.58142 ms - Host latency: 2.74722 ms (end to end 2.79968 ms, enqueue 2.55317 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.83406 ms - Host latency: 3.01787 ms (end to end 3.07483 ms, enqueue 2.80183 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.58318 ms - Host latency: 2.75232 ms (end to end 2.80151 ms, enqueue 2.55088 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.65161 ms - Host latency: 2.82148 ms (end to end 2.87473 ms, enqueue 2.62004 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.56616 ms - Host latency: 2.73713 ms (end to end 2.7926 ms, enqueue 2.53665 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.41606 ms - Host latency: 2.58167 ms (end to end 2.6313 ms, enqueue 2.38938 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.36941 ms - Host latency: 2.53433 ms (end to end 2.5832 ms, enqueue 2.34365 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.30088 ms - Host latency: 2.46367 ms (end to end 2.5115 ms, enqueue 2.2762 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.33689 ms - Host latency: 2.496 ms (end to end 2.5438 ms, enqueue 2.31226 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.26094 ms - Host latency: 2.42258 ms (end to end 2.46948 ms, enqueue 2.23845 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.92202 ms - Host latency: 3.10884 ms (end to end 3.1614 ms, enqueue 2.89385 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.40603 ms - Host latency: 2.57751 ms (end to end 2.62856 ms, enqueue 2.37908 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.4 ms - Host latency: 2.56067 ms (end to end 2.60962 ms, enqueue 2.37385 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.41121 ms - Host latency: 2.5792 ms (end to end 2.63318 ms, enqueue 2.3832 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.39797 ms - Host latency: 2.56562 ms (end to end 2.6146 ms, enqueue 2.37195 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.41541 ms - Host latency: 2.58818 ms (end to end 2.63809 ms, enqueue 2.38762 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.73511 ms - Host latency: 2.92368 ms (end to end 2.97856 ms, enqueue 2.70442 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.47734 ms - Host latency: 2.64299 ms (end to end 2.69399 ms, enqueue 2.44924 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.46343 ms - Host latency: 2.6197 ms (end to end 2.66748 ms, enqueue 2.42102 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.38625 ms - Host latency: 2.54692 ms (end to end 2.59558 ms, enqueue 2.36021 ms)\n",
      "[04/19/2023-10:03:07] [I] Average on 10 runs - GPU latency: 2.43525 ms - Host latency: 2.60049 ms (end to end 2.65088 ms, enqueue 2.40706 ms)\n",
      "[04/19/2023-10:03:07] [I] \n",
      "[04/19/2023-10:03:07] [I] === Performance summary ===\n",
      "[04/19/2023-10:03:07] [I] Throughput: 349.757 qps\n",
      "[04/19/2023-10:03:07] [I] Latency: min = 2.17334 ms, max = 6.27222 ms, mean = 2.75817 ms, median = 2.61951 ms, percentile(99%) = 4.58179 ms\n",
      "[04/19/2023-10:03:07] [I] End-to-End Host Latency: min = 2.21582 ms, max = 6.32983 ms, mean = 2.81277 ms, median = 2.67151 ms, percentile(99%) = 4.6824 ms\n",
      "[04/19/2023-10:03:07] [I] Enqueue Time: min = 1.99561 ms, max = 6.0542 ms, mean = 2.55498 ms, median = 2.42749 ms, percentile(99%) = 4.27328 ms\n",
      "[04/19/2023-10:03:07] [I] H2D Latency: min = 0.0210571 ms, max = 0.149414 ms, mean = 0.0651649 ms, median = 0.0627441 ms, percentile(99%) = 0.0976562 ms\n",
      "[04/19/2023-10:03:07] [I] GPU Compute Time: min = 2.01904 ms, max = 6.08691 ms, mean = 2.58335 ms, median = 2.45416 ms, percentile(99%) = 4.30551 ms\n",
      "[04/19/2023-10:03:07] [I] D2H Latency: min = 0.00769043 ms, max = 0.44989 ms, mean = 0.109655 ms, median = 0.102112 ms, percentile(99%) = 0.207916 ms\n",
      "[04/19/2023-10:03:07] [I] Total Host Walltime: 3.00208 s\n",
      "[04/19/2023-10:03:07] [I] Total GPU Compute Time: 2.71252 s\n",
      "[04/19/2023-10:03:07] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[04/19/2023-10:03:07] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[04/19/2023-10:03:07] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[04/19/2023-10:03:07] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=./saved_model/face_detection_yunet_120x160.onnx\n"
     ]
    }
   ],
   "source": [
    "# check trtexec\n",
    "!/usr/src/tensorrt/bin/trtexec --onnx=./saved_model/face_detection_yunet_120x160.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theanh/Workspace/BK-Consulting-Robot/PINTO_model_zoo/144_YuNet\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theanh/Workspace/BK-Consulting-Robot\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tensorrt-examples'...\n",
      "remote: Enumerating objects: 308, done.\u001b[K\n",
      "remote: Counting objects: 100% (308/308), done.\u001b[K\n",
      "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
      "remote: Total 308 (delta 160), reused 221 (delta 78), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (308/308), 10.71 MiB | 2.76 MiB/s, done.\n",
      "Resolving deltas: 100% (160/160), done.\n",
      "/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples\n",
      "Submodule 'TensorRT' (https://github.com/NobuoTsukamoto/TensorRT-1.git) registered for path 'TensorRT'\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT'...\n",
      "Submodule path 'TensorRT': checked out '0570fe2f643053c2d5915192059166d34407a0f9'\n",
      "Submodule 'parsers/onnx' (https://github.com/onnx/onnx-tensorrt.git) registered for path 'TensorRT/parsers/onnx'\n",
      "Submodule 'third_party/cub' (https://github.com/NVlabs/cub.git) registered for path 'TensorRT/third_party/cub'\n",
      "Submodule 'third_party/protobuf' (https://github.com/protocolbuffers/protobuf.git) registered for path 'TensorRT/third_party/protobuf'\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT/parsers/onnx'...\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT/third_party/cub'...\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT/third_party/protobuf'...\n",
      "Submodule path 'TensorRT/parsers/onnx': checked out '078f20b8fbcbb802aa5ffcd2134519721a61b88c'\n",
      "Submodule 'third_party/onnx' (https://github.com/onnx/onnx.git) registered for path 'TensorRT/parsers/onnx/third_party/onnx'\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT/parsers/onnx/third_party/onnx'...\n",
      "Submodule path 'TensorRT/parsers/onnx/third_party/onnx': checked out '994c6181247d7b419b28889fc57d5817e2089419'\n",
      "Submodule 'third_party/benchmark' (https://github.com/google/benchmark.git) registered for path 'TensorRT/parsers/onnx/third_party/onnx/third_party/benchmark'\n",
      "Submodule 'third_party/pybind11' (https://github.com/pybind/pybind11.git) registered for path 'TensorRT/parsers/onnx/third_party/onnx/third_party/pybind11'\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT/parsers/onnx/third_party/onnx/third_party/benchmark'...\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT/parsers/onnx/third_party/onnx/third_party/pybind11'...\n",
      "Submodule path 'TensorRT/parsers/onnx/third_party/onnx/third_party/benchmark': checked out 'e776aa0275e293707b6a0901e0e8d8a8a3679508'\n",
      "Submodule path 'TensorRT/parsers/onnx/third_party/onnx/third_party/pybind11': checked out '59a2ac2745d8a57ac94c6accced73620d59fb844'\n",
      "Submodule path 'TensorRT/third_party/cub': checked out 'c3cceac115c072fb63df1836ff46d8c60d9eb304'\n",
      "Submodule path 'TensorRT/third_party/protobuf': checked out 'b10d490efd6052a02a90277e3325adbec6ce62eb'\n",
      "Submodule 'third_party/benchmark' (https://github.com/google/benchmark.git) registered for path 'TensorRT/third_party/protobuf/third_party/benchmark'\n",
      "Submodule 'third_party/googletest' (https://github.com/google/googletest.git) registered for path 'TensorRT/third_party/protobuf/third_party/googletest'\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT/third_party/protobuf/third_party/benchmark'...\n",
      "Cloning into '/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/TensorRT/third_party/protobuf/third_party/googletest'...\n",
      "Submodule path 'TensorRT/third_party/protobuf/third_party/benchmark': checked out '5b7683f49e1e9223cf9927b24f6fd3d6bd82e3f8'\n",
      "Submodule path 'TensorRT/third_party/protobuf/third_party/googletest': checked out '5ec7f0c4a113e2f18ac2c6cc7df51ad6afc24081'\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NobuoTsukamoto/tensorrt-examples\n",
    "%cd tensorrt-examples\n",
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "!cp PINTO_model_zoo/144_YuNet/saved_model/face_detection_yunet_120x160.onnx tensorrt-examples/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/python/utils\n",
      "Loading ONNX file from path /home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/models/face_detection_yunet_120x160.onnx...\n",
      "Beginning ONNX file parsing\n",
      "[04/19/2023-10:37:49] [TRT] [W] onnx2trt_utils.cpp:366: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "Completed parsing of ONNX file\n",
      "Building an engine from file /home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/models/face_detection_yunet_120x160.onnx; this may take a while...\n",
      "[04/19/2023-10:39:23] [TRT] [W] Tactic Device request: 134MB Available: 112MB. Device memory is insufficient to use tactic.\n",
      "[04/19/2023-10:39:23] [TRT] [W] Skipping tactic 3 due to insuficient memory on requested size of 134 detected for tactic 4.\n",
      "Completed creating Engine\n"
     ]
    }
   ],
   "source": [
    "%cd tensorrt-examples/python/utils\n",
    "!python3 convert_onnxgs2trt.py \\\n",
    "    --model /home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/models/face_detection_yunet_120x160.onnx \\\n",
    "    --output /home/theanh/Workspace/BK-Consulting-Robot/tensorrt-examples/models/face_detection_yunet_120x160.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../yunet\n",
    "!python3 trt_yunet_capture.py --model ../../models/face_detection_yunet_120x160.trt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General Env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
